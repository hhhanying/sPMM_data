{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from scripts.data_generator_Normal import document_generator \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_to_list(x):\n",
    "    # x is a directory, which only contains np array or const\n",
    "    for i in x.keys():\n",
    "        if type(x[i]) is type(np.array([1])):\n",
    "            x[i] = x[i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 300\n",
    "Ntest = 100\n",
    "mu_Mu, sigma2_Mu, alpha_Lambda, beta_Lambda = 0, 5, 2, 4\n",
    "set_index = 0\n",
    "b = 0.1\n",
    "data_name = \"dataset_{}.txt\"\n",
    "\n",
    "for d in [20,50,100]:\n",
    "    for nlabel in [3, 6, 9]:\n",
    "        for k0 in [2, 5, 10]:\n",
    "            for k1 in [2, 5, 10]:\n",
    "                set_index += 1\n",
    "                dat = {}\n",
    "\n",
    "                dg = k0 + k1 \n",
    "                K = ntopic = nlabel * k0 + k1\n",
    "                alpha = np.ones(dg)\n",
    "                # define T\n",
    "                T = []\n",
    "                for i in range(nlabel):\n",
    "                    tem = np.block([\n",
    "                        [np.zeros((k0 * i, k0 + k1))],\n",
    "                        [np.eye(k0), np.zeros((k0, k1))],\n",
    "                        [np.zeros((k0 * (nlabel - i - 1), k0 + k1))],\n",
    "                        [np.zeros((k1, k0)), np.eye(k1)]\n",
    "                    ])\n",
    "                    T.append(tem)\n",
    "\n",
    "                # draw corpus-level parameters\n",
    "                rho = np.random.dirichlet(alpha, 1)[0]\n",
    "                a = np.random.exponential(1 / b, 1)[0]\n",
    "                Lambda = np.random.gamma(shape = alpha_Lambda, scale = 1 / beta_Lambda, size = (K, d))\n",
    "                Mu = np.random.normal(mu_Mu, np.sqrt(sigma2_Mu / Lambda), (K, d))\n",
    "                Tau = Mu * Lambda\n",
    "\n",
    "                model = {\"a\": a, \"rho\": rho, \"Lambda\": Lambda, \"Mu\": Mu}\n",
    "                dir_to_list(model)\n",
    "\n",
    "                \n",
    "                X, Y, G, U = document_generator(a, rho, T, Lambda, Tau, Ntrain)\n",
    "                training_set = {'X': X, \"Y\": Y, \"G\": G, \"U\":U}\n",
    "                X, Y, G, U = document_generator(a, rho, T, Lambda, Tau, Ntest)\n",
    "                test_set = {'X': X, \"Y\": Y, \"G\": G, \"U\":U}\n",
    "                dir_to_list(training_set)\n",
    "                dir_to_list(test_set)\n",
    "\n",
    "                dat = {\"model\": model, \"training_set\": training_set, \"test_set\": test_set}\n",
    "                with open(data_name.format(str(set_index)), \"w\") as f:\n",
    "                    f.write(json.dumps(dat))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "document_generator() got an unexpected keyword argument 'nrare'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m model \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m: a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrho\u001b[39m\u001b[38;5;124m\"\u001b[39m: rho, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLambda\u001b[39m\u001b[38;5;124m\"\u001b[39m: Lambda, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMu\u001b[39m\u001b[38;5;124m\"\u001b[39m: Mu}\n\u001b[1;32m     37\u001b[0m dir_to_list(model)\n\u001b[0;32m---> 40\u001b[0m X, Y, G, U \u001b[38;5;241m=\u001b[39m \u001b[43mdocument_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrare\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m training_set \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m: X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m: Y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m\"\u001b[39m: G, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m\"\u001b[39m:U}\n\u001b[1;32m     42\u001b[0m X, Y, G, U \u001b[38;5;241m=\u001b[39m document_generator(a, rho, T, Lambda, Tau, Ntest, nrare \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, prob_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: document_generator() got an unexpected keyword argument 'nrare'"
     ]
    }
   ],
   "source": [
    "Ntrain = 300\n",
    "Ntest = 100\n",
    "mu_Mu, sigma2_Mu, alpha_Lambda, beta_Lambda = 0, 5, 2, 4\n",
    "set_index = 0\n",
    "b = 0.1\n",
    "data_name = \"unbalanced_{}.txt\"\n",
    "\n",
    "for d in [20,50,100]:\n",
    "    for nlabel in [3, 6, 9]:\n",
    "        for k0 in [2, 5, 10]:\n",
    "            for k1 in [2, 5, 10]:\n",
    "                set_index += 1\n",
    "                dat = {}\n",
    "\n",
    "                dg = k0 + k1 \n",
    "                K = ntopic = nlabel * k0 + k1\n",
    "                alpha = np.ones(dg)\n",
    "                # define T\n",
    "                T = []\n",
    "                for i in range(nlabel):\n",
    "                    tem = np.block([\n",
    "                        [np.zeros((k0 * i, k0 + k1))],\n",
    "                        [np.eye(k0), np.zeros((k0, k1))],\n",
    "                        [np.zeros((k0 * (nlabel - i - 1), k0 + k1))],\n",
    "                        [np.zeros((k1, k0)), np.eye(k1)]\n",
    "                    ])\n",
    "                    T.append(tem)\n",
    "\n",
    "                # draw corpus-level parameters\n",
    "                rho = np.random.dirichlet(alpha, 1)[0]\n",
    "                a = np.random.exponential(1 / b, 1)[0]\n",
    "                Lambda = np.random.gamma(shape = alpha_Lambda, scale = 1 / beta_Lambda, size = (K, d))\n",
    "                Mu = np.random.normal(mu_Mu, np.sqrt(sigma2_Mu / Lambda), (K, d))\n",
    "                Tau = Mu * Lambda\n",
    "\n",
    "                model = {\"a\": a, \"rho\": rho, \"Lambda\": Lambda, \"Mu\": Mu}\n",
    "                dir_to_list(model)\n",
    "\n",
    "                \n",
    "                X, Y, G, U = document_generator(a, rho, T, Lambda, Tau, Ntrain, nrare = 2, prob_rate = 0.2)\n",
    "                training_set = {'X': X, \"Y\": Y, \"G\": G, \"U\":U}\n",
    "                X, Y, G, U = document_generator(a, rho, T, Lambda, Tau, Ntest, nrare = 2, prob_rate = 0.2)\n",
    "                test_set = {'X': X, \"Y\": Y, \"G\": G, \"U\":U}\n",
    "                dir_to_list(training_set)\n",
    "                dir_to_list(test_set)\n",
    "\n",
    "                dat = {\"model\": model, \"training_set\": training_set, \"test_set\": test_set}\n",
    "                with open(data_name.format(str(set_index)), \"w\") as f:\n",
    "                    f.write(json.dumps(dat))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
