{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from scripts.data_generator_Normal import document_generator \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_to_list(x):\n",
    "    # x is a directory, which only contains np array or const\n",
    "    for i in x.keys():\n",
    "        if type(x[i]) is type(np.array([1])):\n",
    "            x[i] = x[i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 300\n",
    "Ntest = 100\n",
    "mu_Mu, sigma2_Mu, alpha_Lambda, beta_Lambda = 0, 5, 2, 4\n",
    "set_index = 0\n",
    "b = 0.1\n",
    "data_name = \"dataset_{}.txt\"\n",
    "\n",
    "for d in [20,50,100]:\n",
    "    for nlabel in [3, 6, 9]:\n",
    "        for k0 in [2, 5, 10]:\n",
    "            for k1 in [2, 5, 10]:\n",
    "                set_index += 1\n",
    "                dat = {}\n",
    "\n",
    "                dg = k0 + k1 \n",
    "                K = ntopic = nlabel * k0 + k1\n",
    "                alpha = np.ones(dg)\n",
    "                # define T\n",
    "                T = []\n",
    "                for i in range(nlabel):\n",
    "                    tem = np.block([\n",
    "                        [np.zeros((k0 * i, k0 + k1))],\n",
    "                        [np.eye(k0), np.zeros((k0, k1))],\n",
    "                        [np.zeros((k0 * (nlabel - i - 1), k0 + k1))],\n",
    "                        [np.zeros((k1, k0)), np.eye(k1)]\n",
    "                    ])\n",
    "                    T.append(tem)\n",
    "\n",
    "                # draw corpus-level parameters\n",
    "                rho = np.random.dirichlet(alpha, 1)[0]\n",
    "                a = np.random.exponential(1 / b, 1)[0]\n",
    "                Lambda = np.random.gamma(shape = alpha_Lambda, scale = 1 / beta_Lambda, size = (K, d))\n",
    "                Mu = np.random.normal(mu_Mu, np.sqrt(sigma2_Mu / Lambda), (K, d))\n",
    "                Tau = Mu * Lambda\n",
    "\n",
    "                model = {\"a\": a, \"rho\": rho, \"Lambda\": Lambda, \"Mu\": Mu}\n",
    "                dir_to_list(model)\n",
    "\n",
    "                \n",
    "                X, Y, G, U = document_generator(a, rho, T, Lambda, Tau, Ntrain)\n",
    "                training_set = {'X': X, \"Y\": Y, \"G\": G, \"U\":U}\n",
    "                X, Y, G, U = document_generator(a, rho, T, Lambda, Tau, Ntest)\n",
    "                test_set = {'X': X, \"Y\": Y, \"G\": G, \"U\":U}\n",
    "                dir_to_list(training_set)\n",
    "                dir_to_list(test_set)\n",
    "\n",
    "                dat = {\"model\": model, \"training_set\": training_set, \"test_set\": test_set}\n",
    "                with open(data_name.format(str(set_index)), \"w\") as f:\n",
    "                    f.write(json.dumps(dat))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 300\n",
    "Ntest = 100\n",
    "mu_Mu, sigma2_Mu, alpha_Lambda, beta_Lambda = 0, 5, 2, 4\n",
    "set_index = 0\n",
    "b = 0.1\n",
    "data_name = \"unbalanced_{}.txt\"\n",
    "\n",
    "for d in [20,50,100]:\n",
    "    for nlabel in [3, 6, 9]:\n",
    "        for k0 in [2, 5, 10]:\n",
    "            for k1 in [2, 5, 10]:\n",
    "                set_index += 1\n",
    "                dat = {}\n",
    "\n",
    "                dg = k0 + k1 \n",
    "                K = ntopic = nlabel * k0 + k1\n",
    "                alpha = np.ones(dg)\n",
    "                # define T\n",
    "                T = []\n",
    "                for i in range(nlabel):\n",
    "                    tem = np.block([\n",
    "                        [np.zeros((k0 * i, k0 + k1))],\n",
    "                        [np.eye(k0), np.zeros((k0, k1))],\n",
    "                        [np.zeros((k0 * (nlabel - i - 1), k0 + k1))],\n",
    "                        [np.zeros((k1, k0)), np.eye(k1)]\n",
    "                    ])\n",
    "                    T.append(tem)\n",
    "\n",
    "                # draw corpus-level parameters\n",
    "                rho = np.random.dirichlet(alpha, 1)[0]\n",
    "                a = np.random.exponential(1 / b, 1)[0]\n",
    "                Lambda = np.random.gamma(shape = alpha_Lambda, scale = 1 / beta_Lambda, size = (K, d))\n",
    "                Mu = np.random.normal(mu_Mu, np.sqrt(sigma2_Mu / Lambda), (K, d))\n",
    "                Tau = Mu * Lambda\n",
    "\n",
    "                model = {\"a\": a, \"rho\": rho, \"Lambda\": Lambda, \"Mu\": Mu}\n",
    "                dir_to_list(model)\n",
    "\n",
    "                \n",
    "                X, Y, G, U = document_generator(a, rho, T, Lambda, Tau, Ntrain, nrare = 2, prob_rate = 0.2)\n",
    "                training_set = {'X': X, \"Y\": Y, \"G\": G, \"U\":U}\n",
    "                X, Y, G, U = document_generator(a, rho, T, Lambda, Tau, Ntest, nrare = 2, prob_rate = 0.2)\n",
    "                test_set = {'X': X, \"Y\": Y, \"G\": G, \"U\":U}\n",
    "                dir_to_list(training_set)\n",
    "                dir_to_list(test_set)\n",
    "\n",
    "                dat = {\"model\": model, \"training_set\": training_set, \"test_set\": test_set}\n",
    "                with open(data_name.format(str(set_index)), \"w\") as f:\n",
    "                    f.write(json.dumps(dat))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
